{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Start with 100 neurons. membrane_potential[i] is the membrane potential of\\n   neuron i.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from scipy import sparse\n",
    "\n",
    "class Network:\n",
    "    \"\"\" Construct a recurrent neural network (based on the Sussillo implementation cited\n",
    "        in the README). The network is described by time_constant, or the time steps\n",
    "        in the overall evolution of the network, num_neurons, or the number of neurons\n",
    "        in the network, chaotic_constant, or the stabilizing weighting constant that\n",
    "        allows for chaotic activity in the network.\n",
    "        \n",
    "        [...explain other input variables...]\n",
    "        readout_sparseness = p_z in paper\n",
    "        g_z is an output constant scaling factor\n",
    "    \"\"\"\n",
    "    def __init__(self, time_constant, num_neurons, p, chaotic_constant, input_num, \n",
    "                 output_num, gg_sparseness, gz_sparseness, fg_sparseness, readout_sparseness,\n",
    "                 g_gz, dt):\n",
    "        # evolution time constant\n",
    "        self.time_constant = time_constant\n",
    "        \n",
    "        # number of neurons in the network\n",
    "        self.num_neurons = num_neurons\n",
    "        \n",
    "        # chaotic constant. Sussillo recommends chaotic_constant = 1.5 to allow for chaotic dynamics\n",
    "        self.chaotic_constant = chaotic_constant\n",
    "        \n",
    "        # membrane potentials of each neurons (what should this be initialized to?)\n",
    "        self.membrane_potential = 0.5 * numpy.random.rand(num_neurons) # neurons\n",
    "        print(\"array of zeros supposedly\", self.membrane_potential)\n",
    "        \n",
    "        # number of input neurons\n",
    "        self.input_num = input_num\n",
    "        \n",
    "        # number of output neurons\n",
    "        self.output_num = output_num\n",
    "        \n",
    "        # Connectivity matrix dictating synaptic strength of connections between neurons \n",
    "        # in the network. (J^{GG} in the paper), gg_sparseness is inter-neuron sparsenesss.\n",
    "        scale = 1.0 / numpy.sqrt(p * num_neurons)\n",
    "        self.connectivity_matrix = scale * chaotic_constant * sparse.rand(num_neurons, num_neurons, density=(1-gg_sparseness)).toarray()\n",
    "        \n",
    "        # Connectivity matrix dictating synaptic strength of connections between neurons\n",
    "        # in the network and readout neurons\n",
    "        self.feedout_matrix = sparse.rand(output_num, num_neurons, density=(1-gz_sparseness)).toarray()\n",
    "        \n",
    "        # Connectivity matrix dictating synaptic strength of connections between neurons\n",
    "        # in the network and feedin neurons\n",
    "        self.feedin_matrix = sparse.rand(input_num, num_neurons, density=(1-fg_sparseness)).toarray()\n",
    "        \n",
    "        # the vector w in Sussillo\n",
    "        self.readout_matrix = sparse.rand(output_num, 1, density=(1-readout_sparseness)).toarray()\n",
    "        \n",
    "        # r(t)\n",
    "        self.network_activities = sparse\n",
    "        \n",
    "        # J^{G_z} (unsure of dimension here)\n",
    "        self.z_matrix = 2 * (numpy.random.rand(num_neurons, 1) - 0.5)\n",
    "        \n",
    "        # scaling factor for z\n",
    "        self.g_gz = g_gz\n",
    "        self.dt = dt\n",
    "        \n",
    "    \"\"\" Propogate the feedback input in z through the network. This models the differential\n",
    "        equation presented in Sussillo. z is the dot product of w and r(t) (see definitions above)\n",
    "    \"\"\"\n",
    "    def prop(self, z, r):\n",
    "        for neuron in range(self.num_neurons):\n",
    "            g_GG = self.chaotic_constant\n",
    "            x_i = self.membrane_potential[neuron]\n",
    "            \n",
    "            y_0 = 0\n",
    "            for n in range(self.num_neurons):\n",
    "                y_0 += self.connectivity_matrix[neuron][n] * r[n] # numpy.tanh(self.membrane_potential[n])\n",
    "            \n",
    "            # first term in network equation\n",
    "            # y_0 *= g_GG\n",
    "            \n",
    "            # second term\n",
    "            y_1 = self.g_gz * self.z_matrix[neuron] * z * dt\n",
    "            self.membrane_potential[neuron] = (1.0 - self.time_constant) * x_i + y_0 * dt + y_1\n",
    "\n",
    "\"\"\"Start with 100 neurons. membrane_potential[i] is the membrane potential of\n",
    "   neuron i.\"\"\"\n",
    "# network = Network(0.001, 1000, 1.7, 10, 10, 0.9, 0.9, 0.9, 0.1, 0.2)\n",
    "# network.prop(0.009)\n",
    "# print(type(network.connectivity_matrix))\n",
    "# print(network.membrane_potential[:])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
